# first step parameters
## path to the input file, should be a pickle file storing a list of words
input_filepath:

## number of tokens in the training vocabulary
## used when creating vocab if min_freq is not set
vocab_size: 54059

## minimum frequency of a token to be in vocabulary 
min_freq: 3

## size of the context window
window_size: 10
## the number of paritions to divide cooccurence matrix in 
num_partitions: 10
## chunk size of h5py.Dataset
chunk_size: 1000000

# when used in first step, specify the output directory of cooccurrence entries
# when used in second step, specify where to read cooccurrence entries from
cooccurrence_dir:

# second step parameters
## output path for the trained word vectors 
output_folder:
## pytorch training parameters
batch_size: 32
start_epoch: 0
end_epoch: 2
device: cpu
learning_rate: 0.05
## glove paremeters
embedding_size: 300
x_max: 100
alpha: 0.75

## pre-trained weights path
pre_trained_weights:
